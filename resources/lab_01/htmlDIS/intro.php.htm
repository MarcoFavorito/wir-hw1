<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Introduction to Netlab</title>

<link rel="stylesheet" type="text/css" href="intro.php_files/astonuni.css">
<link rel="stylesheet" type="text/css" href="intro.php_files/netlab_style.css">
<insert file="netlab_tags.txt" nocache=""></insert>

<meta http-equiv="Content-Type" content="text/html;
charset=iso-8859-1"></head>
 <body>

<p> </p><img src="intro.php_files/netlogo.gif" alt="Netlab logo" align="top" height="50"><p> </p> <hr> <p> </p>

<br>
<table width="100%">
<tbody><tr valign="top">
<td rowspan="2" align="center">
<hr><a class="link_style" href="http://www.ncrg.aston.ac.uk/netlab/index.php">Welcome</a><hr><a class="link_style" href="http://www.ncrg.aston.ac.uk/netlab/news.php">News</a><hr><a class="link_style" href="http://www.ncrg.aston.ac.uk/netlab/down.php">Downloads</a><hr><a class="link_style" href="http://www.ncrg.aston.ac.uk/netlab/over.php">Overview and Examples</a><hr><a class="link_style" href="http://www.ncrg.aston.ac.uk/netlab/intro.php">How to Use</a><hr><a class="link_style" href="http://www.ncrg.aston.ac.uk/netlab/book.php">Book and Resources</a><hr><a class="link_style" href="http://www.ncrg.aston.ac.uk/netlab/contrib.php">Contributions</a><hr><a class="link_style" href="http://www.ncrg.aston.ac.uk/netlab/bugs.php">Bugs</a><hr><a class="link_style" href="http://www.ncrg.aston.ac.uk/netlab/links.php">Links</a><hr></td>

<td></td>

<td>
<h1>How to use Netlab</h1>

Of course, one of the best ways of learning how to use Netlab is to run and
examine the demo programs.  Every major function in the library has at
least one associated demonstration. Each demo has the prefix <code>dem</code>
in its name.
<p>
Two demos that are particularly useful
when getting started are
</p><ul>
<li> <code>demnlab</code> is a simple GUI that allows you to select and
    run Netlab demos
</li><li> <code>demtrain</code> demonstrates how a neural network can be
    trained to solve classification and regression problems: it reads in
    datasets in the <a href="#DataFormat">Netlab data format.</a>
</li></ul>

<a name="Models and Structures"><h3>Models and Structures</h3></a>

Every model of any complexity (all except K nearest neighbour) is manipulated
as a Matlab data structure.  This ensures that all the relevant information
is kept together, and prevents the user from passing models to the wrong
function. Each model has a `constructor' function that builds and initialises
the relevant data structure.  Each model has a three letter prefix that is
used for all of its associated functions. 
<p>
For example, the Gaussian mixture model has the prefix <code>gmm</code>.
A call to the constructor
</p><pre>net = gmm(1, 2, 'spherical');
</pre>
generates the following data structure
<pre>          type: 'gmm'
           nin: 1
      ncentres: 2
       nparams: 6
    covar_type: 'spherical'
        priors: [0.5000 0.5000]
       centres: [2x1 double]
        covars: [1 1]
</pre>
We have not developed the code in a fully object oriented fashion for
simplicity.  To access fields in this structure, for example, the
centres, use the <code>.</code> operator:
<pre>net.centres
</pre>
The models have been designed to have compatible data structures. The
Gaussian mixture model is used when training RBF networks and in
Mixture Density Networks.
<p>
Because models are represented by a single data structure, it
is very easy to save and load them. The command
</p><pre>save gmm.net net
</pre>
saves the Gaussian mixture model <code>net</code> to the file
<code>gmm.net</code>.

<a name="Training and Optimisers"><h3>Training and Optimisers</h3></a>

The optimisers are compatible with the Matlab optimisation toolbox.
In particular, they make use of the <code>options</code> vector to
control the way the algorithm works, set termination conditions etc.
(For more information on the meaning of the fields in this vector,
see the Matlab help on <code>foptions</code> and the help for each
optimisation function.)  There is one significant difference in the
treatment of termination criteria.  If the tolerance is set to 0, then
in Netlab, the optimisation function will continue until the required
number of steps have been taken, whereas in Matlab, the values are
overwritten with the default <code>1e-4</code>.  All Netlab optimisation
routines assume that there is a function available that computes the
gradient of the function being optimised.
<p>
Because the optimisers (with the exception of the on-line gradient descent
optimiser <code>olgd</code> which is specifically for training network
models) are general purpose, they operate in `parameter vector' space.
However, the model parameter vectors are held in the corresponding data
structure.  To apply the optimisers to network training, three utility
functions <code>netopt,  neterr, netgrad</code> are provided.
Examples of their use can be found in <code>demmlp1.m</code>. For example,
use the following line of code
to train a network data structure with input data <code>x</code> and
target data <code>t</code> using the quasi-Newton training algorithm
</p><pre>[net, options] = netopt(net, options, x, t, 'quasinew');
</pre>
This mechanism relies upon the following assumptions:
<ul>
  <li> The network data structure <code>net</code> contains the
function prefix (for example,
      <code>mlp</code>) in a field called <code>type</code>.
  </li><li> The function that computes the error is called
      <code>&lt;prefix&gt;err</code>,
      for example <code>mlperr</code>.
  </li><li> The function that computes the error gradient is called
      <code>&lt;prefix&gt;grad</code>,
      for example <code>mlpgrad</code>.
  </li><li> There is function <code>&lt;prefix&gt;pak</code> (for example,
      <code>mlppak</code>) which packs all the component parameter vectors
      in the network data structure into one single vector.
  </li><li> There is function <code>&lt;prefix&gt;unpak</code> (for example,
      <code>mlpunpak</code>) which unpacks a single parameter vector
      into its component vectors in a network data structure.
</li></ul>
If you extend Netlab by adding new models, then you should ensure that
you follow these conventions if you want to use optimisation functions to
train them.

<a name="A Simple Program"><h3>A Simple Program</h3></a>

The "Hello world" equivalent in Netlab is a programme that generates
some data, trains an MLP, and plots its predictions.
<pre>% Generate the matrix of inputs x and targets t.
x = [0:1/19:1]';
t = sin(2*pi*x) + 0.2*randn(ndata, 1);

% Set up network parameters.
net = mlp(1, 3, 1, 'linear');

% Set up vector of options for the optimiser.
options = zeros(1,18);
options(1) = 1;			% This provides display of error values.
options(9) = 1;			% Check the gradient calculations.
options(14) = 100;		% Number of training cycles. 

% Train using scaled conjugate gradients.
[net, options] = netopt(net, options, x, t, 'scg');

% Plot the trained network predictions.
plotvals = [0:0.01:1]';
y = mlpfwd(net, plotvals);
plot(plotvals, y, 'ob')
</pre>
A fuller version of this program is contained in <code>demmlp1.m</code>

<a name="DataFormat"> <h3>Data Format and Sample Datasets</h3></a>

As well as the usual Matlab data file formats, Netlab provides two
utility functions <code>datread</code> and <code>datwrite</code> to
read and write data files respectively.  The data is stored in a text
file with a short header followed by the data itself.  The header
has the form
<pre>nin   2
nout  1
ndata 12
</pre>
where <code>nin</code> specifies the number of input variables,
<code>nout</code> the number of output variables, and <code>ndata</code>
the number of data points.
Each subsequent line corresponds to a single example, with the first
<code>nin</code> values for the input variables, and the remaining
<code>nout</code> values for the output variables.  For unsupervised learning
problems, <code>nout</code> can be zero.
<p>
Netlab is supplied with two datasets: the ubiquitous exclusive or problem
<code>xor.dat</code>, and oil pipeline data <code>oilTrn.dat</code> and
<code>oilTst.dat</code>.  The latter is synthetic data modelling non-intrusive
measurements on a pipeline transporting a mixture of oil, water and gas.
the inputs are twelve measures of gamma beam attenuation, and the two outputs
represent the fraction of water and the fraction of oil.  Each dataset contains
500 examples.
<a href="http://www.ncrg.aston.ac.uk/cgi-bin/tr_search?logic=AND&amp;year=93&amp;show_abstract=on&amp;format=HTML&amp;title=%27multi-phase%27">
This link</a> gives references to papers that use the data.
</p></td>
</tr>
</tbody></table>

<hr><author><em>This page is maintained by <a href="http://www.ncrg.aston.ac.uk/People/nabneyit/Welcome.html">Ian Nabney</a></em> (<a href="mailto:i.t.nabney@aston.ac.uk"><tt>i.t.nabney@aston.ac.uk</tt></a>)</author><hr><address>Neural Computing Research Group<br>Information Engineering<br>Aston University<br>Birmingham B4 7ET<br>United Kingdom<p>Phone: +44 (0)121 359 3611 x. 4685<br>Fax: +44 (0)121 333 6215</p></address><hr><!-- hhmts start -->
Last modified: Thurs Nov 13 2003
<!-- hhmts end -->

</body></html>