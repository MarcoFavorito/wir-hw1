   <HTML><HEAD> <TITLE>Learning Feature Weights for CBR:Global
  versus Local</TITLE></HEAD>
  <H2>Learning Feature Weights for CBR:Global versus Local</H2>
  <H4>Bonzano,
  Cunningham,
  and Smyth</H4>
  k-Nearest Neighbour is a popular case retrieval technique in Case-Based
  Reasoning. It has the disadvantage that its accuracy depends strongly on
  the weights assigned to the case features. This problem can be addressed by
  using Introspective Learning to discover appropriate values for feature
  weights. The basic idea with Introspective Learning (IL) is to examine cases
  that are similar in order to discover which features are important and which
  are not. The only problem with this idea is that there are a myriad of ways
  in which weights can be updated based on this kind of analysis. There are
  several different cues that can trigger a weight change; there are several
  ways in which the weights can be changed and there is the added
  complication that weights can be global or local. In this paper we report
  some analysis of IL in a CBR system for conflict resolution in Air Traffic
  Control. We show that local weights are best in this particular domain and
  we show which update cues are most effective. We also show that overfitting
  can be a problem with IL and we discuss how it can be avoided.
  <PRE>
  @inproceedings{A32,
  title = {Learning Feature Weights for CBR:Global versus Local},
  author = {Bonzano and Cunningham and Smyth},
  year = {1997},
  booktitle = {Fifth Conference of the Italian Association for Artificial
  Intelligence (AI*IA97)},
  }
  </PRE>
  <P>

