<HTML xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns="http://www.w3.org/TR/REC-html40"><HEAD><TITLE>Manifesto della scienza semplice</TITLE>
<META http-equiv=Content-Type content="text/html; charset=windows-1252">
<STYLE>BODY {
    BACKGROUND: #666666; MARGIN: 0px; COLOR: black; FONT-FAMILY: Verdana, Arial, sans-serif
}
.blogtitle {
    FONT-SIZE: 32px; MARGIN-BOTTOM: 1px; MARGIN-LEFT: 20px; COLOR: white; FONT-FAMILY: Verdana, Arial, sans-serif
}
.links {
    FONT-SIZE: 11px; FONT-FAMILY: Verdana, Arial, sans-serif
}
A.links:hover {
    COLOR: white
}
A {
    FONT-WEIGHT: bold; TEXT-DECORATION: none
}
A:hover {
    COLOR: red
}
.date {
    FONT-WEIGHT: bold; FONT-SIZE: 16px; MARGIN: 10px; COLOR: black; FONT-FAMILY: Verdana, Arial, sans-serif
}
.posts {
    FONT-SIZE: 12px; MARGIN: 10px; COLOR: black; FONT-FAMILY: Verdana, Arial, sans-serif
}
.byline {
    FONT-SIZE: 11px; COLOR: #999999; FONT-FAMILY: Verdana, Arial, sans-serif
}
</STYLE>

<SCRIPT language=JavaScript>
<!--

function SymError()
{
  return true;
}

window.onerror = SymError;

var SymRealWinOpen = window.open;

function SymWinOpen(url, name, attributes)
{
  return (new Object());
}

window.open = SymWinOpen;

//-->
</SCRIPT>

<META content="Microsoft FrontPage 5.0" name=GENERATOR>
</HEAD>
<BODY vLink=#003366 aLink=#FF0000 link=#336699 bgColor=#666666 marginheight="0" 
marginwidth="0">
<DIV align=center style="width: 1374; height: 507"><span style="font-size: 9pt"><BR>
  </span>
<TABLE cellSpacing=0 cellPadding=0 width="1374" border=0>
  <TBODY>
  <TR>
    <TD vAlign=bottom bgColor=#336699 height=65 width="828">
      &nbsp;<DIV class=blogtitle><B><span style="font-size: 9pt"><br>
        </span>Stili di ricerca: teorie &quot;fondamentali&quot; e modelli 
        &quot;fenomenologici&quot; <span style="font-size: 9pt"><br>
        <br>
&nbsp;</span></B></DIV></TD></TR>
  <TR>
    <TD vAlign=top width=757 bgColor=#cccccc>
      <p>&nbsp;</p>
      <blockquote>
      <p><font face="Arial" size="2">Sotto il profilo teorico sono state 
      essenzialmente le difficoltà a far rientrare la biologia ed i processi 
      cognitivi all’interno di un approccio riduzionistico a guidare&nbsp; verso la 
      nozione di apertura logica, ossia l’insufficienza di poter comprendere le 
      strutture viventi- e dunque anche i processi cognitivi- considerando 
      soltanto l’apertura termodinamica; è necessario invece considerare i molti 
      livelli di interazione sistema-ambiente ed il gioco di vincoli legati 
      all’inter-relazione tra i due. I fenomeni genuinamente emergenti, non 
      riconducibili ad una semplice &quot;somma&quot; lineare delle parti in gioco, hanno 
      a che fare con un livello molto alto di apertura logica, in grado di 
      considerare esplicitamente il gran numero di stimoli-risposte di un 
      sistema biologico situato in un ambiente. Un esempio si trova nella 
      robotica evolutiva, dove il &quot;sistema cognitivo&quot; del robot cresce in 
      complessità man mano che l’interazione con il mondo diventa sempre più 
      ampia, fino a produrre comportamenti impredicibili a partire dall’analisi 
      dello stato iniziale robot + mondo.<br>
      <br>
      Un tentativo teorico interessante di cogliere questi aspetti peculiari dei 
      sistemi viventi è stato fatto da Maturana e Varela con la loro teoria 
      dell’autopoiesi, centrata su due punti fondamentali: <br>
      1) il vivente è una forma di organizzazione caratterizzata da relazioni a 
      più livelli tra gli elementi che costituiscono il sistema;<br>
      b) un sistema vivente ha un hardware in grado di sostenere tramite 
      dissipazione ed accrescimento della struttura materiale i vari livelli di 
      organizzazione.<br>
      <br>
      E’ interessante notare la convergenza tra questa visione e la nozione di 
      apertura logica, poiché è ben rimarcato che un processo vivente non è la 
      sua struttura materiale, ma questa piuttosto è il &quot;supporto&quot; di una 
      complessa rete di relazioni dinamiche.<br>
      Queste teorie oggi sono messe alla prova dal gran numero di dati 
      sperimentali che costituisce il &quot;cuore&quot; della biologia moderna, e che è 
      esemplificato dalle varie aree in rapida espansione, le cosiddette 
      &quot;omics&quot;: genomics, proteomics, metabolomics, e così via. In tutti questi 
      casi si pone il problema di comprendere in che modo un sistema, ad esempio 
      il DNA, è funzionalmente connesso ad altri sistemi, come la rete di 
      interazioni proteiche, e questi ultimi, a loro volta, sono aspetti di reti 
      ancora più complesse, come i processi metabolici.<br>
      <br>
      Ogni modello matematico &quot;chiuso&quot;, per quanto raffinato esso sia, che non 
      tiene conto di questo &quot;interfacciamento&quot; tra sistemi diversi, è destinato 
      a successi parziali che progressivamente possono trasformarsi facilmente 
      in false piste. Come è stato notato da Leroy Hood e Hwa Lim, oggi la 
      biologia sta passando da una fase di acquisizione di dati a quella 
      dell’organizzazione degli stessi in contesti teorici coerenti; passo 
      necessario anche dal punto di vista di applicativo, che richiede lo 
      sviluppo di nuovi strumenti di lavoro teorici. In alcuni campi è 
      particolarmente evidente che l'adozione di un modello piuttosto che un 
      altro presuppone delle scelte sugli &quot;stili di ricerca&quot;. Qui vogliamo 
      soffermarci brevemente sulle differenze tra i sostenitori delle &quot;teorie 
      fondamentali&quot; e i più pragmatici studiosi di modelli - a volte detti 
      &quot;galleggianti&quot;- in relazione al nostro progetto di &quot;scienza 
      semplice&quot;.Utilizzeremo come esempi il folding protein e la struttura 
      dell'acqua.<br>
      <br>
      Com’è noto, per folding protein si intende quel complesso di 
      trasformazioni strutturali spontanee che portano una macromolecola da una 
      struttura disordinata a quella struttura tridimensionale in cui è in grado 
      di svolgere le sue funzioni. E’ plausibile ritenere che queste 
      imprevedibili configurazioni dipendano in modo complesso dall’ambiente in 
      cui la proteina è immersa. Si tratta dunque di un classico problema di 
      apertura logica, e di quella che viene definita emergenza intrinseca. Non 
      esistono a tutt’oggi teorie &quot;fondamentali&quot; in grado di fare predizioni 
      efficaci su queste &quot;aggrovigliate&quot; trasformazioni, teorie basate, ad 
      esempio, sulle caratteristiche &quot;microscopiche&quot; atomico-molecolari. Bisogna 
      dunque ricorrere a strumenti &quot;globali&quot; di tipo mesoscopico, basati 
      essenzialmente su tecniche statistiche in grado di offrire una buona 
      corrispondenza tra topologie , tempi osservati e calcolo della loro 
      probabilità di realizzarsi. Nel caso del folding protein si stanno 
      dimostrando di grande utilità le rei neurali, proprio per la loro 
      vocazione di sistemi dinamici in grado di connettere una configurazione in 
      input con una di output.<br>
      <br>
      <br>
      Da un punto di vista epistemologico si è fatta spesso una distinzione 
      troppo netta tra teorie &quot;fondamentali&quot; da una parte, in grado di offrire 
      spiegazioni dettagliate in base ad una ben definita gerarchia di 
      conoscenza acquisite sui vari livelli della fenomenologia in studio, e 
      modelli &quot;fenomenologici&quot;, che fanno uso di strumenti statistici e 
      computazionali, i quali suggeriscono &quot;correlazioni&quot; e &quot;vanno bene finché 
      non si trova qualcosa di meglio&quot;. Vediamo adesso con un pò d'attenzione, i 
      pregi ed i limiti dei due approcci.<br>
      <br>
      Senza pretendere in alcun modo una definizione rigorosa, una spiegazione 
      basata su una teoria fondamentale è un modello derivato da un più vasto 
      corpus di conoscenze consolidato.Dunque la validità del modello è in un 
      certo senso &quot;garantita&quot;, ed al tempo stesso &quot;vincolata&quot;, ad una struttura 
      teorica molto radicata, che ha un ampio raggio di applicazioni e &quot;regge&quot; 
      una fenomenologia osservativo-sperimentale estremamente diversificata. Un 
      esempio classico è dato dallo sviluppo della fisica quantistica , che 
      permise di derivare da una sola equazione, l'equazione di Schrodinger, 
      fenomeni diversi, come l'effetto fotoelettrico, gli atomi idrogenoidi, 
      l'effetto tunnell, e così via. Il vantaggio di un modello basata su una 
      teoria di questo tipo è piuttosto evidente:con un unico &quot;grimaldello&quot; 
      concettuale è possibile non soltanto analizzare molti fenomeni, ma vedere 
      in quale modo sono connessi l'uno all'altro. Del resto, è anche vero che 
      in questo modo lo sviluppo successivo della ricerca trova una sua &quot;strada 
      principale&quot; che può rivelarsi a volte limitativa sotto almeno due punti di 
      vista 1) Ogni modello &quot;eredita&quot; una serie di opzioni concettuali di base 
      dal nucleo teorico centrale, e queste possono rivelarsi dei veri e propri 
      vincoli nell'adozione di nuove prospettive. Restando nel campo della 
      fisica quantistica, ci limitiamo qui a ricordare il problema 
      dell'interpretazione probabilistica in contesti quali l'EPR-Bell e le 
      correlazioni non-locali o l'uso di probabilità negative. Queste situazioni 
      impongono dei delicati lavori di &quot;manutenzione&quot; nei &quot;sotterranei&quot; della 
      teoria, il cui obiettivo è quello di migliorare l'efficacia dell'apparato 
      teorico senza perdere i vantaggi acquisiti. Inutile dire che questi lavori 
      sui &quot;fondamenti&quot; possono essere lunghi, difficili e frustranti; 2) A volte 
      il passaggio tra le equazioni &quot;fondamentali&quot; ed i problemi specifici del 
      modello è un passo molto complicato, e persino poco utile. Nessuno 
      utilizzerebbe le equazioni dell'elettrodinamica quantistica per analizzare 
      la caratteristiche di un circuito elettrico! In questo caso le poche 
      formule &quot;chiuse&quot; derivate dalle equazioni di Maxwell sono più che 
      sufficienti.Un altro caso è dato dal &quot;caos dinamico&quot;, dove il problema non 
      nasce da insufficienze nelle meccanica classica, ma nelle relazioni con le 
      condizioni iniziali ed al contorno per sistemi hamiltoniani che descrivono 
      forme &quot;radicali&quot; di non-linearità.<br>
      I modelli &quot;galleggianti&quot; (usiamo questo termine non nel senso 
      dispregiativo, ma proprio perchè non pongono il problema di trovare 
      &quot;radici&quot; in una qualche teoria &quot;profonda&quot;), vanno incontro invece ad altri 
      pregi e naturalmente pongono invece altri problemi. In questi casi lo 
      studio del modello è strettamente mirato al fenomeno. Cosa vuol dire 
      questo? Che il modello ha come aspirazione principale, se non unica, 
      quello di correlare una certa sequenza di input-output tratti da un certo 
      quadro osservativo-sperimentale, e fare eventualmente delle previsioni 
      azzeccate all'interno dello stesso quadro.Questo approccio ha 
      evidentemente una grande flessibilità, e l'uso di strumenti di tipo 
      statistico può rivelare una grande &quot;trasportabilità&quot; da un campo ad 
      un'altro totalmente differente. Ad esempio,come è già accaduto spesso, 
      dalla biologia allo studio dei fenomeni sociali, alla linguistica.I 
      limiti, invece, possono essere focalizzati tramite il seguente 
      ragionamento. All'interno di ogni set sperimentale si ricavano una serie 
      di dati finiti di tipo x1, x2, x3,...; xn, con x misura di un evento, 
      ossia un intervallo di numeri razionali(misura+/- errore medio). Si può 
      dimostrare che per ogni sequenza finita di Xi esiste sempre un numero 
      infinito di polinomi di tipo F(xi)=0 in grado di interpolare il numero 
      finito di dati. E' chiaro che se costruissimo così un modello, per una 
      stessa sequenza di dati, avremmo infinite equazioni &quot;buone&quot;, che possono 
      ottenersi con semplici software matematici in grado di trovare questi 
      polinomi , come ad esempio Maple, Mathematica, o strumenti simili, a 
      disposizione di ogni utente informatico.Quale scegliere tra tutte? Ad 
      esempio la più breve e compatta, seguendo un criterio di compressione 
      algoritmica.In questo modo avremmo una semplice proposizione matematica 
      che&nbsp;mette in relazione tutti i dati significativi.Ma naturalmente questo 
      risultato è insoddisfacente, poichè ci porterebbe ad una scienza 
      frammentata in tanti &quot;modelli ad hoc&quot; costruiti sul fenomeno definito 
      all'interno di un quadro osservativo prefissato&nbsp;.&nbsp;Ad un modello matematico 
      chiediamo&nbsp; non soltanto delle sequenze matematiche che correlano i dati 
      ottenuti, ma anche previsioni, ipotesi&nbsp;affidabili sull'andamento del 
      fenomeno in domini diversi,&nbsp;connessioni tra aree diverse della conoscenza, 
      insomma una forma di comprensione più&nbsp;&quot;ampia&quot;&nbsp;Per &quot;selezionare&quot; 
      un'equazione &quot;buona&quot; da tutte quelle ottenibili, è necessario dunque fare 
      un pò di lavoro teorico, ad esempio formulando delle ipotesi sulla 
      dinamica del fenomeno, sulle sue caratteristiche generali, su ciò che ci 
      si può aspettare variando i parametri in gioco.<br>
      <br>
      <br>
      Un esempio è dato dal problema della struttura dell'acqua, e delle sue 
      preziose anomalie (preziose per il ruolo che hanno per la vita; ricordiamo 
      qui il comportamento della densità tra 0 e 4 gradi Celsius, la viscosità 
      ad alte pressioni, la tensione superficiale molto elevata, i valori delle 
      transizioni di fase,la costante dielettrica molto elevata).<br>
      Non esiste a tutt'oggi un'unica teoria in grado di spiegare tutte le 
      caratteristiche dell'acqua liquida. Diversi modelli vengono utilizzati a 
      seconda del problema in gioco. Per una comprensione strutturale della 
      singola molecola la teoria quantistica degli orbitali molecolari è 
      sufficiente. Il vero problema nasce quando si considerano i comportamenti 
      collettivi di molte molecole.Esistono 3 grandi classi di modelli: 
      discontinui(Frank-Wen, dal 1957), continui(Pope, dal 1951),statistici. Nel 
      primo tipo si considerano dei cluster molecolari tenuti assieme da un 
      legame ad idrogeno che si distruggono e riformano in continuazione con 
      l'agitazione termica.Nei modelli continui si ipotizza che lo stato liquido 
      è caratterizzato da una particolare &quot;distorsione&quot; del legame idrogeno.Nei 
      modelli &quot;puramente&quot; statistici si assegna arbitrariamente la distribuzione 
      delle cariche all'interno della molecola, e si calcola poi che tipo di 
      &quot;assestamento&quot; può subire questa distribuzione in relazione ai valori in 
      gioco dei parametri essenziali. Si tratta, com'è evidente, con modelli 
      dalle &quot;vocazioni&quot; esplicative molto diverse. Il modello a cluster spiega 
      bene molte proprietà &quot;ordinarie&quot;, i modelli continui sono efficaci nello 
      studio delle transizioni di fase e delle conseguenti modificazioni dello 
      spettro vibrazionale, quelli statistici, infine, nonostante l'apparente 
      &quot;ingenuità&quot; teorica, hanno permesso di studiare molte situazioni 
      &quot;anomale&quot;.<br>
      Può esistere un modello teorico &quot;forte&quot; dell'acqua liquida? Una proposta 
      in questa direzione è arrivata nel 1988 da G. Preparata ed E. Del Giudice 
      sulla base dell'elettrodinamica quantistica, basata sui &quot;domini di 
      coerenza&quot;, una sorta di &quot;atomi&quot; della materia condensata, che spiegano con 
      grande accuratezza le correlazioni long-range e la formazione dei cluster, 
      tramite una descrizione basata su un sistema di dipoli interagenti. Anche 
      qui, però, si trova la difficoltà tradizionale dei modelli teorici basati 
      sui &quot;principi primi&quot; della teoria dei campi: il problema di trovare 
      soluzioni non-perturbative (esatte, chiuse), è piuttosto arduo, cosa che 
      fa preferire ancora agli studiosi dell'acqua le classi di modelli 
      &quot;galleggianti&quot;(è il caso di dirlo....!) tradizionali.<br>
      Analogamente per molti problemi di fisica nucleare ( i modelli del nucleo 
      atomico sono legione).<br>
      Un atteggiamento ragionevole sarebbe dunque quello di cercare la 
      connessione con i principi &quot;primi&quot; laddove questa strada sia evidente e 
      percorribile, ma non dimenticare l'utilità di modelli che tengono in conto 
      anche una grossa fetta d'informazione che gli approcci &quot;fondamentali&quot; 
      tendono a sottovalutare, ossia che ogni osservazione è sempre &quot;situata&quot;, 
      impone cioè molto di più che l'applicazione delle &quot;leggi fondamentali&quot;, e 
      bisogna fare i conti con il gran numero di vincoli e opzioni da fare 
      quando si affronta un problema specifico in un quadro sperimentale 
      fissato.<br>
      <br>
      La questione fondamentale/fenomenologico si pone in modo ancora più forte 
      per le cosidette &quot;Teorie del Tutto&quot;, quelle rivolte ad unificare le teorie 
      di base in una costruzione ancora più compatta in grado di comprendere 
      teoria quantistica e relatività, con modificazioni/estensioni/superamenti 
      dell'una o dell'altra teoria: twistors, superstrings, teoria dei 
      loops,etc.In questo caso, ad es. la relatività generale, che oggi è 
      considerata la teoria &quot;principe&quot; della gravitazione, diverrebbe una teoria 
      fenomenologica, le cui radici &quot;stanno altrove&quot;! Tra l'altro, quando si 
      entra &quot;dentro&quot; queste teorie, si ha il forte sospetto che siano tutte 
      varianti di un solo schema, per far emergere il quale probabilmente sarà 
      necessario un mutamento di paradigma (es. spazio -tempo discreto, con 
      geometria &quot;adatta&quot;), e le difficoltà matematiche e sperimentali 
      giustificano ampiamente il fatto che ad occuparsi di queste aree piuttosto 
      &quot;esoteriche&quot; siano un pugno di teorici. <br>
      Il dato curioso, dal punto di vista della comunicazione scientifica, è che 
      a questi tentativi che persino un super-teorico come Penrose definisce 
      &quot;provvisori&quot; (ossia&quot;lavori in corso&quot;, &quot;pericolo di crolli&quot;!), i media 
      danno un gran peso( i giornali di divulgazione sono pieni di multiversi 
      con 11 o 27 dimensioni!), mentre si assiste continuamente ad un 
      appiattimento sistematico di aree più &quot;giovani&quot; e di fascino teorico 
      indubbio, di sottile complessità e con impatto tecnologico non minore, 
      come il citato problema del &quot;dialogo&quot; tra DNA e proteine.<br>
      &nbsp;C'è da chiedersi se si tratti di genuina attitudine speculativa nel 
      &quot;lettore di cose scientifiche&quot;, o se piuttosto attraverso imprese così 
      &quot;onnicomprensive&quot; e &quot;globali&quot; non si cerchi per l'ennesima volta di 
      accreditare presso il pubblico- che è poi colui che &quot;paga&quot; la ricerca e ne 
      dovrebbe beneficiare intellettualmente e praticamente- la visione 
      ciclopica della big-science, le sue strutture tecno-burocratiche,i suoi 
      modelli di investimento.Infine, queste teorie si propongono 
      ingannevolmente come &quot;definitive&quot;. <br>
      <br>
      <br>
      In realtà,i fenomeni di emergenza intrinseca tipici dei sistemi viventi e 
      dei processi cognitivi ci insegnano proprio che una &quot;teoria definitiva&quot;, 
      un singolo modello matematico valido per ogni range, può non esistere, o 
      può esistere ed essere poco utile e &quot;maneggevole&quot;! Quale dev'essere dunque 
      il rapporto tra teorie &quot;fondamentali&quot; e &quot;modelli&quot; legati ad uno specifico 
      range? Sicuramente non di tipo &quot;deduttivo&quot;. Abbiamo visto che è piuttosto 
      raro derivare analiticamente le soluzioni &quot;mirate&quot;&nbsp;che interessano 
      direttamente da una teoria generale.Del resto un modello &quot;ad hoc&quot; può 
      risultare piuttosto &quot;miope&quot; se non sono chiare le sue connessioni con il 
      corpus generale delle conoscenze. Bisogna allora adottare una logica di 
      &quot;compatibilità&quot;: il modello non deve essere in contrasto con la teoria più 
      generale e consolidata (ma se questo accade, ben venga! Una domanda in più 
      da porsi).L'avanzare della ricerca, poi, restingerà naturalmente il numero 
      dei modelli possibili secondo un principio di selezione, che il più delle 
      volte non riguarderà tanto la &quot;verità&quot; o &quot;falsità&quot; del modello in assoluto 
      (perchè la scienza non procede secondo gli schemi elementari di Carnap o 
      Popper!), ma la sua applicabilità e fecondità più o meno ampie.<br>
      Il confronto con i sistemi logicamente aperti ci ricorda che 
      l’intelligenza della Natura non può essere &quot;catturata&quot; da un’unica teoria, 
      e la Physis dev'essere piuttosto una pluralità di strategie cognitive in 
      relazione all’infinita sorgente di problemi posta dal mondo.</font></p>
      <p><i><font size="2">Ignazio Licata</font></i></p>
      &nbsp;</p>